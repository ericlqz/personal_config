# 绪论
  * 前言(背景)
    * 信息爆炸(信息泛滥、信息超载、信息浪费)
    * 缺乏信息分析的能力
      * 找不到自己想要看的内容
      * 内容庞杂，无法一一识别
      * 观点五花八门没有参考意义
  * 目的(提出问题，明确、具体)
  * 理论背景(推荐算法发展介绍)
  * 研究范围(需要解决的问题)
  * 研究方法(测试集、指标)
  * 章节安排
# 相关技术
  * 相关技术成果(LFM、LDA、ML)
# 系统设计
  * 总体规划(结合相关技术解决研究范围)
   

一、导言
1.1 前言
    借助于互联网技术的发展，信息的制造、采集、传播速度以及规模达到了空前的水平。从门户网站，到微博，到社交媒体，到博客，再到各种各样的网站，人类所拥有的信息量以指数函数的速度急剧增加，倍增的时间周期越来越短。信息爆炸是人们对这一现象的一种形象化描述，也是人们对于在单位空间及时间内急剧增加的信息的担忧。
    最初人们的信息阅读来自报纸、书藉，而信息的泛滥引起人们头脑的混乱，让人无法信赖的信息越来越多。资讯的信息量已经超过了个人所能接收及处理的能力。人们对于信息的反应能力远远低于信息传播的速度;资讯媒介中的信息量远远超过人们所能消费处理的信息量;大量的无关的各式各样的质量不一的信息严重干扰了人们对于有用信息的分辨率及正确选择。个人用于接受、处理信息的时间及能力是有限的，而资讯媒介传播资讯的时间和能量是可以无限扩展的。这就造成了信息超载的问题。
    信息作为一种特殊的资源，人类应该予以很好地开发和利用，但由于真正有价值的信息被大量的无用信息所淹没，求知的人不得不耗费大量的时间和精力来对待信息洪水，这种大海捞针式搜寻的结果是，经常无奈地让一些有用信息与大量无用信息一起从身旁流走，从而造成了信息浪费。令人担忧的不仅是信息量过于庞大造成的信息浪费，而且是信息内容的支离破碎、凌乱不堪，这种被应接不暇的信息填满的生活让当代人身陷泥潭、精神疲惫。
1.2 目的
    为了解决信息过载的问题，已经有无数科学家和工程提出了很多天才的解决方案,其中代表性的解决方案是分类目录和搜索引擎。随着互联网规模的不断扩大，分类目录网站网络也只能少量的热门网站，不能满足用户的需求。而搜索引擎需要用户主动提供准确的关键词来寻找信息，因为不能解决用户的很多其他需求，比如当用户无法找到准确描述自己需求的关键词时，搜索引擎就无能为力了。
    信息过载的问题困扰着人们对于资讯获取的需求。如何使人们及时获取有用的、感兴趣的、有价值的资讯？这一问题，引发了我们对于资讯发现的再思考,个性化推荐的概念也随之而出。
    我们需要一个个性化的资讯服务，根据用户的历史阅读行为数据，学习用户的兴趣分布及兴趣演化，根据用户的兴趣及资讯的类别及质量为用户推荐资讯。
1.3 理论背景
    为了让推荐结果符合用户品味，我们需要深入了解用户。首先，很多时候用户并不知道自己喜欢，或者很难用语言描述自己喜欢什么;其次，用户的兴趣是不断变化的。因此，我们需要通过算法自动发掘用户行为数据，从用户的行为中推测出用户的兴趣，从而给用户推荐他们感兴趣的资讯。
    用户的行为不是随机的，而是蕴含着很多模式。其中最著名的例子就是啤酒和尿布的例子。用户行为中蕴涵着很多不是那么显而易见的理解，而个性化推荐算法的任务就是通过计算机去发现这些规律。
    基于用户行为分析的推荐算法是个性化推荐系统的重要算法，学术界一般将这种类型的算法称为协同过滤算法。顾名思义，协同过滤就是指用户可以齐心协力，通过不断地和网站互动，使自己的推荐列表能够不断过滤自己不感兴趣的资讯，从而越来越满足自己的需求。
    作为个性化推荐系统核心的协同过滤算法，最初应用于新闻组中，根据用户下载的新闻计算他们之间在品味上的相似程度，并利用这种相似程度为他们进一步推荐相关的新闻。
1.4 研究范围
    本文将着眼于基于协同过滤的算法设计并实现一个个性化资讯推荐系统。通过机器学习，实现基于用户行为统计及资讯内容的自动聚类，为用户实时推送感兴趣的高质量资讯。
1.5 评测方法
    对于推荐系统主要有3种评测方法-离线实验、用户实验和在线实验。在本系统中将通过离线实验方法评测提到的算法。采用公开数据集。离线实验如下设计。首先，将用户行为数据集按照均匀分布随机分成M份，挑选一份作为测试集，将剩下的M-1份作为训练集。然后在训练集上建立用户兴趣模型，并在测试集上对用户行为进行预测，统计出相应的评测指标。为了保证评测指标并不是过拟合的结果，需要进行M次实验，并且每次都使用不同的测试集。然后将M次实验测出的评测指标的平均值作为最终的评测指标。
    评测的性能指标包括：准确率/召回率，新颖度，实时性等。
二、相关技术
2.1 Collaborative Filtering(协同过滤)
    协同过滤(Collaborative Filtering)又叫社会过滤，由Goldberg等人在1992年首先提出，并应用在研究型邮件推荐系统Tapestry中。协同过滤推荐的核心思想是认为用户的兴趣偏好是可以通过对具有类似行为或偏好的用户群进行分析和预测得出的，强调人与人之间的协作。
    协同过滤推荐技术可以说是从人的角度进行推荐，算法的个性化程度高，能够为用户发现新兴趣，实现兴趣的跳跃性推荐。
    在大型的推荐系统中，由于项目数量的规模迅速扩大，评分矩阵的超高维和稀疏特性日益严重，导致了推荐质量的下降;另外随着用户数量的递增，传统的协同过滤技术在计算量上面临瓶颈问题，在实时推荐方面也显示出了局限性，因此，近些年，一些学者提出了基于模型的推荐算法，此类算法首先依据众多用户历史的评分矩阵训练得到了一个模型，当目标用户到达时，利用该离线模型为用户进行推荐预测。基于模型的协同过滤算法广泛的使用了各种机器学习技术。
    
2.1 Latent Semantic Analysis
    潜在语义分析(Latent Semantic Analysis, LSA)是1988年贝尔通信实验室的Susan T.Dumais等人撰写的“Using Latent Semantic Analysis to Improve Access to Textual Information"一文中首次提出的一种新的信息检索代数模型，是用于知识获取和展示的计算理论与方法。LSA是关于知识归纳和知识表征的新理论，也是利用大型文本语料库及统计计算方法提取和表征词汇语境意义的一种理论和方法。最常用在文档检索中，它使用统计计算的方法对大量的文本集进行分析，从而提取出词与词之间潜在的语义结构，并用这种潜在的语义结构来表示词和文本，从而比较有效地解决了自然语言的模糊性带来的问题，达到消除词之间的相关性和简化文本向量，实现降维的目的。
    LSA是在传统向量空间模型方法(Vector Space Model)的基础上发展起来的。在LSA中对文本的表示和检索充分考虑了词语间的相关性，采用了对词语和文本间的内部关系同时建模的方法，在多维空间中用微量表示文本。LSA计算出文件集中的词汇-文本矩阵中最重要的正交维数，通过奇异值分解，将文本向量投影到如此计算出的低维子空间中，并通过计算投影到低维子空间间的向量间的角度来对词语和文本的相似性进行比较，而相似度反映了词语和文本间存在的相关关系。
    LSA不同于传统的自然语言处理和人工智能程序，它不使用人工字典、知识库、语义网、语法等，它把输入全当作原始的文本，这些文本会被解析成独特字串。LSA的基本观点是:把高维的向量空间模型(VSM)表示中的文档映射到低维的潜在语义空间中。这个映射是通过对项/文档矩阵的奇异值分解(SVD)来实现的。具有可计算性强、需要人的参与少等优点，可以弥补VSM向量分析方法的不足。
2.2 Latent Dirichlet Allocation
    LDA(Latent Dirichlet Allocation)是David M.Blei等人在2003年提出的，属于生成模型，是文本建模的一种方法。LDA可以随机生成一篇由所有主题组成的文章。通过文本的建模，可以对文本进行特征选择、主题分类、判断相似度等。在上世纪90年代提出的LSA中，通过对向量空间进行降维，获得文本的潜在语义空间。LDA模型采用了词袋(bag of words)的方法，该方法将每一篇文本视为一个词频向量，从而将文本信息转化为易于建模的数字信息。
    和传统的语义模型相比，LDA模型更符合现实世界中的文本的特点。LDA是一个三层贝叶斯概率模型，包含词、主题和文档三层结构，LDA将每个文档表示为一个主题混合，每个主题是固定词表上的一个多项式分布。LDA假设文档由主题混合产生，同时每个主题是在固定词表上的一个多项式分布;这些主题被集合中的所有文档共享;每个文档有一个特定的主题混合比例(Topic Proportion)，从Dirichlet分布中抽样准备下豆。作为一种产生式文模型，用LDA提取文档的隐含语义结构和文档表征已经成功的应用到很多文本相关的领域。
2.3 Machine Learning
    机器学习(Machine Learning)是研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。
    机器学习是近20多年兴起的一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。机器学习理论主要是设计和分析一些让计算机可以自动“学习”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。机器学习已经有了十分广泛的应用，例如：数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA序列测序、语音和手写识别、战略游戏和机器人运用。
    
